{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9357813,"sourceType":"datasetVersion","datasetId":5673265}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Check what's already installed\n!pip list | grep -E \"faiss|cuml|cupy\"\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T16:55:09.387362Z","iopub.execute_input":"2025-04-26T16:55:09.387975Z","iopub.status.idle":"2025-04-26T16:55:11.274490Z","shell.execute_reply.started":"2025-04-26T16:55:09.387952Z","shell.execute_reply":"2025-04-26T16:55:11.273784Z"}},"outputs":[{"name":"stdout","text":"cuml-cu12                          25.2.1\ncupy-cuda11x                       13.4.1\ncupy-cuda12x                       13.4.1\nfaiss-cpu                          1.10.0\nlibcuml-cu12                       25.2.1\nSat Apr 26 16:55:11 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   34C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   32C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\"\"\"\nHieroglyph Recognition – paper‑faithful implementation with optional GPU (cuML + FAISS)\n\n* Follows Franken & van Gemert, \"Automatic Egyptian Hieroglyph Recognition\n  by Retrieving Images as Texts\", ACM MM 2013.\n* Uses cuML MiniBatchKMeans and FAISS‑GPU when a CUDA device is present\n  (Kaggle \"GPU (T4 ×2)\" runner). Falls back to scikit‑learn / CPU otherwise.\n* Expects a directory tree like::\n\n        data/\n            A1/\n                img_0001.png\n                img_0002.png\n            D36/\n                ...\n  e.g. the Kaggle dataset mounted under\n        /kaggle/input/egyptian-hieroglyphics-datasets\n\"\"\"\nimport os\nimport warnings\nfrom pathlib import Path\nfrom typing import List, Tuple\n\nimport cv2\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom skimage.feature import hog\nfrom sklearn.preprocessing import normalize\n\n\n# -------------------------------------------------------------------------\n# 0 · optional GPU back‑ends\n# -------------------------------------------------------------------------\nGPU_AVAILABLE = False\ntry:\n    # Try to use pre-installed GPU libraries\n    import cupy as cp\n    \n    # Try to access cuML's KMeans\n    try:\n        from cuml.cluster import KMeans as cuKMeans\n    except ImportError:\n        # Alternative import path\n        try:\n            from cuml.cluster import MiniBatchKMeans as cuKMeans\n        except ImportError:\n            print(\"Using sklearn KMeans instead of cuML\")\n            from sklearn.cluster import MiniBatchKMeans as cuKMeans\n    \n    # Use CPU version of FAISS\n    import faiss\n    print(\"Using FAISS CPU version with cupy\")\n    \n    # We'll simulate GPU acceleration with CPU FAISS + cupy\n    GPU_AVAILABLE = True\n    \nexcept Exception as e:\n    warnings.warn(f\"GPU libraries not found – falling back to CPU. Error: {str(e)}\")\n    # Always import these for CPU fallback\n    from sklearn.cluster import MiniBatchKMeans\n    from sklearn.neighbors import NearestNeighbors\n\n# fallback CPU k‑means\ndef _cpu_kmeans(n_clusters=200):\n    return MiniBatchKMeans(n_clusters=n_clusters,\n                          batch_size=16384,\n                          max_iter=100,\n                          random_state=0)\n\n# -------------------------------------------------------------------------\n# 1 · Localisation + pre‑processing   (Sec 3·1)\n# -------------------------------------------------------------------------\nclass Localiser:\n    def __init__(self, min_size: int = 10, y_thresh: int = 20):\n        self.min_size = min_size\n        self.y_thresh = y_thresh\n\n    def _bboxes(self, img: np.ndarray) -> List[Tuple[int, int, int, int]]:\n        if img.ndim == 3:\n            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        else:\n            gray = img\n        bin_img = cv2.adaptiveThreshold(gray, 255,\n                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                                        cv2.THRESH_BINARY_INV, 11, 2)\n        bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE,\n                                   np.ones((3, 3), np.uint8))\n        cnts, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL,\n                                   cv2.CHAIN_APPROX_SIMPLE)\n        b = []\n        for c in cnts:\n            x, y, w, h = cv2.boundingRect(c)\n            if w > self.min_size and h > self.min_size:\n                b.append((x, y, x + w, y + h))\n        return b\n\n    def reading_order(self, bboxes):\n        if not bboxes:\n            return []\n        # sort vertically then right‑to‑left per line\n        bboxes.sort(key=lambda b: b[1])\n        lines, cur = [], []\n        for bb in bboxes:\n            if not cur:\n                cur.append(bb)\n            elif abs(bb[1] - cur[-1][1]) < self.y_thresh:\n                cur.append(bb)\n            else:\n                lines.append(cur); cur = [bb]\n        if cur:\n            lines.append(cur)\n        ordered = []\n        for ln in lines:\n            ln.sort(key=lambda b: -b[0])\n            ordered.extend(ln)\n        return ordered\n\n    def cut(self, img: np.ndarray, bb, size=(50, 75)):\n        x1, y1, x2, y2 = bb\n        patch = img[y1:y2, x1:x2].copy()\n        if patch.ndim == 2:\n            patch = cv2.cvtColor(patch, cv2.COLOR_GRAY2BGR)\n        h, w = patch.shape[:2]\n        tgt_h, tgt_w = size[1], size[0]\n        scale = tgt_h / h\n        patch = cv2.resize(patch, (int(w * scale), tgt_h))\n        pad = tgt_w - patch.shape[1]\n        if pad > 0:\n            left = pad // 2\n            patch = cv2.copyMakeBorder(patch, 0, 0, left, pad - left,\n                                       cv2.BORDER_REPLICATE)\n        else:\n            patch = patch[:, (-pad)//2:(-pad)//2 + tgt_w]\n        return patch\n\n# -------------------------------------------------------------------------\n# 2 · Descriptors   (Sec 3·2)\n# -------------------------------------------------------------------------\nclass Descriptors:\n    def __init__(self, hog_bins=8, hog_cells=(4, 4), rings=3, segs=8):\n        self.h_bins = hog_bins\n        self.h_cells = hog_cells\n        self.sc_rings = rings\n        self.sc_segs = segs\n        # Fixed dimensions for outputs\n        self.hog_dim = self.h_bins * self.h_cells[0] * self.h_cells[1]\n        self.sc_dim = self.sc_rings * self.sc_segs\n\n    # ---- HOG\n    def _hog(self, img):\n        if img.ndim == 3:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        # First resize to make consistent dimensions\n        img = cv2.resize(img, (64, 64))  # Standardize to 64x64\n        h, w = img.shape\n        fd = hog(img,\n                 orientations=self.h_bins,\n                 pixels_per_cell=(h // self.h_cells[0],\n                                  w // self.h_cells[1]),\n                 cells_per_block=(1, 1),\n                 feature_vector=True)\n        return normalize(fd.reshape(1, -1))[0]\n\n    # ---- Shape‑Context   (edge histogram)\n    def _sc(self, img):\n        if img.ndim == 3:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        # First resize to make consistent dimensions\n        img = cv2.resize(img, (64, 64))  # Standardize to 64x64\n        edges = cv2.Canny(img, 100, 200)\n        pts = np.column_stack(np.where(edges > 0))\n        if len(pts) < 5:\n            return np.zeros(self.sc_rings * self.sc_segs)\n        centre = np.array([img.shape[0] / 2, img.shape[1] / 2])\n        max_r = np.linalg.norm(centre)\n        r_bins = np.logspace(0, np.log10(max_r), self.sc_rings + 1)\n        a_bins = np.linspace(0, 2*np.pi, self.sc_segs + 1)\n        hist = np.zeros((self.sc_rings, self.sc_segs))\n        for p in pts:\n            v = p - centre\n            r = np.linalg.norm(v)\n            t = np.arctan2(v[0], v[1]) % (2*np.pi)\n            r_i = np.searchsorted(r_bins, r) - 1\n            a_i = np.searchsorted(a_bins, t) - 1\n            if 0 <= r_i < self.sc_rings and 0 <= a_i < self.sc_segs:\n                hist[r_i, a_i] += 1\n        return (hist / (hist.sum() + 1e-9)).ravel()\n\n    # ---- HOOSC = HOG + SC\n    def vector(self, img, mode=\"hoosc\"):\n        # Ensure consistent output dimensions by standardizing the image first\n        if img is None or img.size == 0:\n            # Handle empty images\n            if mode == \"hog\":\n                return np.zeros(self.hog_dim)\n            elif mode == \"sc\":\n                return np.zeros(self.sc_dim)\n            else:  # hoosc\n                return np.zeros(self.hog_dim + self.sc_dim)\n        \n        if mode == \"hog\":   \n            return self._hog(img)\n        if mode == \"sc\":    \n            return self._sc(img)\n        if mode == \"hoosc\":\n            hog_feat = self._hog(img)\n            sc_feat = self._sc(img)\n            return normalize(np.hstack([hog_feat, sc_feat]).reshape(1, -1))[0]\n        raise ValueError(mode)\n\n\n# -------------------------------------------------------------------------\n# 3 · Matcher   (Sec 3·3)  – single/HOG or BoW+χ² (GPU)\n# -------------------------------------------------------------------------\nclass Matcher:\n    def __init__(self, desc_type=\"hoosc\", scheme=\"single\", vocab=200):\n        self.desc_type = desc_type\n        self.scheme = scheme\n        self.vocab = vocab\n        self.desc = Descriptors()\n\n    # ------------------------------------------------------------------\n    def fit(self, imgs: List[np.ndarray], labels: List[str]):\n        self.labels = np.asarray(labels)\n        # global descriptors\n        self.glob = np.vstack([self.desc.vector(im, self.desc_type)\n                               for im in tqdm(imgs, desc=\"global desc\")]).astype(\"float32\")\n    \n        # Use CPU FAISS but still benefit from cupy for other operations\n        if 'faiss' in globals():\n            d = self.glob.shape[1]\n            self.idx_glob = faiss.IndexFlatL2(d)\n            self.idx_glob.add(self.glob)\n            print(\"Using CPU FAISS for indexing\")\n        else:\n            self.nn = NearestNeighbors(n_neighbors=5, metric=\"euclidean\")\n            self.nn.fit(self.glob)\n    \n        # Build BoW if requested\n        if self.scheme == \"bow\":\n            patches = self._collect_patches(imgs)\n            if GPU_AVAILABLE and 'cp' in globals():\n                # Use cupy to accelerate KMeans calculation even with CPU FAISS\n                try:\n                    km = cuKMeans(n_clusters=self.vocab, random_state=0)\n                    patches_gpu = cp.asarray(patches)\n                    km.fit(patches_gpu)\n                    self.centers = cp.asnumpy(km.cluster_centers_)\n                except Exception as e:\n                    print(f\"Error with cuML KMeans: {str(e)}, falling back to CPU\")\n                    # Make sure we're using the properly imported MiniBatchKMeans\n                    from sklearn.cluster import MiniBatchKMeans\n                    km = MiniBatchKMeans(n_clusters=self.vocab, \n                                        batch_size=16384,\n                                        max_iter=100,\n                                        random_state=0).fit(patches)\n                    self.centers = km.cluster_centers_\n            else:\n                km = _cpu_kmeans(self.vocab).fit(patches)\n                self.centers = km.cluster_centers_\n            \n            # Generate BOW histograms for all images\n            self.bows = np.vstack([self._bow_hist(im) for im in tqdm(imgs, desc=\"building BoW\")]).astype(\"float32\")\n            \n            # Apply Hellinger kernel (square root) for chi-square similarity\n            sqrt_bow = np.sqrt(self.bows)  # Define sqrt_bow before using it!\n            \n            if 'faiss' in globals():\n                d_b = sqrt_bow.shape[1]\n                self.idx_bow = faiss.IndexFlatL2(d_b)\n                self.idx_bow.add(sqrt_bow)\n            else:\n                self.nn_bow = NearestNeighbors(n_neighbors=5, metric=\"euclidean\")\n                self.nn_bow.fit(sqrt_bow)\n\n    # ------------------------------------------------------------------\n    def _collect_patches(self, imgs):\n        all_desc = []\n        for im in imgs:\n            h, w = im.shape[:2]; ps = max(8, min(h, w)//4)\n            for y in range(0, h-ps, ps//2):\n                for x in range(0, w-ps, ps//2):\n                    all_desc.append(self.desc._hog(im[y:y+ps, x:x+ps]))\n        return np.asarray(all_desc, dtype=\"float32\")\n\n    def _bow_hist(self, img):\n        h, w = img.shape[:2]; ps = max(8, min(h, w)//4)\n        hist = np.zeros(self.vocab, dtype=\"float32\")\n        for y in range(0, h-ps, ps//2):\n            for x in range(0, w-ps, ps//2):\n                d = self.desc._hog(img[y:y+ps, x:x+ps])\n                c = np.argmin(((self.centers - d)**2).sum(1))\n                hist[c] += 1\n        s = hist.sum()\n        if s > 0: hist /= s\n        return hist\n\n    # ------------------------------------------------------------------\n    def query(self, img, topk=5):\n        q = self.desc.vector(img, self.desc_type).astype(\"float32\").reshape(1,-1)\n        if 'faiss' in globals():\n            D, I = self.idx_glob.search(q, topk)\n            scores = 1/(1+D[0])\n        else:\n            D, I = self.nn.kneighbors(q, n_neighbors=topk)\n            scores = 1/(1+D[0])\n        return [(self.labels[i], float(scores[k])) for k,i in enumerate(I[0])]\n\n\n# -------------------------------------------------------------------------\n# 4 · Simple driver\n# -------------------------------------------------------------------------\ndef load_dataset(root: Path):\n    exts = {\".png\", \".jpg\", \".jpeg\", \".bmp\"}\n    imgs, labels = [], []\n    for p in root.rglob(\"*\"):\n        if p.suffix.lower() not in exts:\n            continue\n        # label = last directory name ('A1' etc.)\n        cls = p.parent.name\n        img = cv2.imread(str(p))\n        if img is not None:\n            imgs.append(img)\n            labels.append(cls)\n    return imgs, labels\n\n\nif __name__ == \"__main__\":\n    # --- Installation of dependencies ---\n    # First cell in Kaggle notebook should include:\n    # !pip install -q opencv-python scikit-image tqdm cuml faiss-gpu cupy\n    \n    # --- Check for GPU ---\n    print(f\"GPU Available: {GPU_AVAILABLE}\")\n    \n    # --- Set paths for Kaggle ---\n    DATA = Path(\"/kaggle/input/glyphdataset/Dataset\")\n    TRAIN = DATA / \"Manual\"  # Actual training root\n    \n    # If the path doesn't exist, print available directories to help debugging\n    if not TRAIN.exists():\n        print(f\"Warning: {TRAIN} doesn't exist\")\n        print(\"Available directories:\")\n        for path in Path(\"/kaggle/input\").glob(\"**/*\"):\n            if path.is_dir() and not path.name.startswith('.'):\n                print(f\"  {path}\")\n        \n        # Try to find an alternative path\n        alt_paths = list(Path(\"/kaggle/input\").glob(\"**/images\"))\n        if alt_paths:\n            TRAIN = alt_paths[0]\n            print(f\"Using alternative path: {TRAIN}\")\n\n    # Load the dataset\n    print(f\"Looking for data in: {TRAIN}\")\n    imgs, lbls = load_dataset(TRAIN)\n    if not imgs:\n        raise RuntimeError(f\"No PNG/JPG files found under {TRAIN}\")\n\n    print(f\"Loaded {len(imgs)} glyph crops from {len(set(lbls))} classes\")\n\n    # Create matcher and fit\n    print(\"Creating and fitting matcher...\")\n    matcher = Matcher(desc_type=\"hoosc\", scheme=\"bow\", vocab=200)\n    matcher.fit(imgs, lbls)\n\n    # Test with a few sample images\n    print(\"\\nTesting recognition with a few samples:\")\n    for i in range(min(5, len(imgs))):\n        res = matcher.query(imgs[i], 3)\n        print(f\"Sample {i} ({lbls[i]}) → {res}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:31:31.577073Z","iopub.execute_input":"2025-04-26T17:31:31.577755Z","iopub.status.idle":"2025-04-26T17:53:18.911389Z","shell.execute_reply.started":"2025-04-26T17:31:31.577725Z","shell.execute_reply":"2025-04-26T17:53:18.910597Z"}},"outputs":[{"name":"stdout","text":"Using FAISS CPU version with cupy\nGPU Available: True\nLooking for data in: /kaggle/input/glyphdataset/Dataset/Manual\nLoaded 8420 glyph crops from 10 classes\nCreating and fitting matcher...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"global desc:   0%|          | 0/8420 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fbe02c7f54c4591be574137c967d223"}},"metadata":{}},{"name":"stdout","text":"Using CPU FAISS for indexing\nError with cuML KMeans: module 'cuml' has no attribute 'global_settings', falling back to CPU\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"building BoW:   0%|          | 0/8420 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a589bb11970948d4be5ca1e736f22f73"}},"metadata":{}},{"name":"stdout","text":"\nTesting recognition with a few samples:\nSample 0 (7) → [('7', 1.0), ('5', 0.9705153703689575), ('5', 0.9685636758804321)]\nSample 1 (7) → [('7', 1.0), ('22', 0.9656131863594055), ('22', 0.9626771807670593)]\nSample 2 (7) → [('7', 1.0), ('21', 0.9664347171783447), ('7', 0.9643725156784058)]\nSample 3 (7) → [('7', 1.0), ('21', 0.9759568572044373), ('23', 0.9694253206253052)]\nSample 4 (7) → [('7', 1.0), ('9', 0.9667506217956543), ('22', 0.9655954837799072)]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}